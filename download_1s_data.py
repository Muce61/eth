#!/usr/bin/env python3
"""
ä»Binance Data Portalä¸‹è½½aggTradesæ•°æ®å¹¶è½¬æ¢ä¸º1ç§’Kçº¿
æ—¶é—´èŒƒå›´: 2024-12-01 åˆ° 2025-12-01
"""
import requests
import pandas as pd
import gzip
import shutil
from pathlib import Path
from datetime import datetime, timedelta
import time
import io
import zipfile

# Top 50 ç²¾é€‰å¸ç§
TIER1_MAJOR = [
    'BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'SOLUSDT', 
    'XRPUSDT', 'ADAUSDT', 'AVAXUSDT', 'DOGEUSDT'
]

TIER2_HIGH_VOL = [
    'MATICUSDT', 'LINKUSDT', 'DOTUSDT', 'UNIUSDT',
    'LTCUSDT', 'BCHUSDT', 'ATOMUSDT', 'ETCUSDT',
    'XLMUSDT', 'FILUSDT', 'TRXUSDT', 'AAVEUSDT',
    'ALGOUSDT', 'ICPUSDT', 'NEARUSDT'
]

TIER3_ACTIVE = [
    '1000PEPEUSDT', '1000SHIBUSDT', 'BONKUSDT', 'FLOKIUSDT',
    'WIFUSDT', 'PENDLEUSDT', 'STXUSDT', 'INJUSDT',
    'SUIUSDT', 'APTUSDT', 'ARBUSDT', 'OPUSDT',
    'IMXUSDT', 'LDOUSDT', 'RNDRUSDT', 'GRTUSDT', 'SANDUSDT'
]

TIER4_RESEARCH = [
    'VIRTUALUSDT', 'ENAUSDT', 'TRUMPUSDT', 'ASTERUSDT',
    'HYPEUSDT', 'ZECUSDT', 'HBARUSDT', 'PNUTUSDT',
    'ONDOUSDT', 'WLDUSDT'
]

TOP_50 = TIER1_MAJOR + TIER2_HIGH_VOL + TIER3_ACTIVE + TIER4_RESEARCH

# Binance Data Portal URL
BASE_URL = "https://data.binance.vision/data/futures/um/daily/aggTrades"

def download_aggtrades(symbol, date_str, output_dir):
    """
    ä¸‹è½½å•æ—¥aggTradesæ•°æ®
    
    URLæ ¼å¼: 
    https://data.binance.vision/data/futures/um/daily/aggTrades/BTCUSDT/BTCUSDT-aggTrades-2024-12-01.zip
    """
    url = f"{BASE_URL}/{symbol}/{symbol}-aggTrades-{date_str}.zip"
    
    try:
        # print(f"  ä¸‹è½½ {symbol} {date_str}... ", end='', flush=True)
        response = requests.get(url, timeout=30)
        
        if response.status_code == 200:
            # æ£€æŸ¥æ˜¯å¦æ˜¯XMLé”™è¯¯ (Binanceæœ‰æ—¶è¿”å›200ä½†å†…å®¹æ˜¯XML Error)
            if response.content.startswith(b'<?xml') or response.content.startswith(b'<Error>'):
                # print(f"âœ— XML Error")
                return None
                
            # ä¿å­˜ZIPæ–‡ä»¶
            zip_path = output_dir / f"{symbol}-{date_str}.zip"
            with open(zip_path, 'wb') as f:
                f.write(response.content)
            
            # print(f"âœ“ ({len(response.content)//1024}KB)")
            return zip_path
        else:
            # print(f"âœ— HTTP {response.status_code}")
            return None
            
    except Exception as e:
        # print(f"âœ— {str(e)[:50]}")
        return None

def extract_and_convert_to_1s(zip_path, output_dir):
    """
    è§£å‹ZIPå¹¶å°†aggTradesè½¬æ¢ä¸º1ç§’Kçº¿
    """
    try:
        # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆZIP
        if not zipfile.is_zipfile(zip_path):
            # print(f"    æ— æ•ˆZIPæ–‡ä»¶: {zip_path.name}")
            zip_path.unlink() # åˆ é™¤æ— æ•ˆæ–‡ä»¶
            return 0
            
        # è§£å‹ZIP
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            # è·å–CSVæ–‡ä»¶å
            csv_name = zip_ref.namelist()[0]
            
            # è¯»å–CSV
            with zip_ref.open(csv_name) as csv_file:
                df = pd.read_csv(csv_file)
        
        # è½¬æ¢æ—¶é—´æˆ³ä¸ºdatetime (åˆ—åæ˜¯ transact_time)
        df['timestamp'] = pd.to_datetime(df['transact_time'], unit='ms')
        df['second'] = df['timestamp'].dt.floor('1s')  # Fix: 1S -> 1s
        
        # æŒ‰ç§’èšåˆ
        klines_1s = df.groupby('second').agg({
            'price': ['first', 'max', 'min', 'last'],
            'quantity': 'sum'
        }).reset_index()
        
        klines_1s.columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume']
        
        # ä¿å­˜1ç§’Kçº¿
        # zip_path.stem æ ¼å¼: BTCUSDT-2024-12-01
        parts = zip_path.stem.split('-')
        if len(parts) >= 4:
            symbol = parts[0]
            date_str = f"{parts[1]}-{parts[2]}-{parts[3]}"
        else:
            # Fallback
            symbol = zip_path.stem.split('-')[0]
            date_str = zip_path.stem.replace(f"{symbol}-", "")
            
        output_file = output_dir / f"{symbol}-{date_str}.csv"
        
        klines_1s.to_csv(output_file, index=False)
        
        # åˆ é™¤ZIPæ–‡ä»¶ä»¥èŠ‚çœç©ºé—´
        zip_path.unlink()
        
        return len(klines_1s)
        
    except Exception as e:
        print(f"    è½¬æ¢å¤±è´¥: {e}")
        return 0

def process_single_date(args):
    """å¤„ç†å•ä¸ªæ—¥æœŸçš„ä»»åŠ¡ (ç”¨äºå¤šçº¿ç¨‹)"""
    symbol, date, raw_dir, processed_dir = args
    date_str = date.strftime('%Y-%m-%d')
    
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
    output_file = processed_dir / f"{symbol}-{date_str}.csv"
    if output_file.exists():
        return 1  # å·²å­˜åœ¨
    
    # ä¸‹è½½
    zip_path = download_aggtrades(symbol, date_str, raw_dir)
    
    if zip_path:
        # è½¬æ¢
        rows = extract_and_convert_to_1s(zip_path, processed_dir)
        return rows if rows > 0 else 0
    return 0

def merge_daily_to_monthly(symbol, year, month, processed_dir, monthly_dir):
    """åˆå¹¶å•æ—¥æ–‡ä»¶ä¸ºæœˆåº¦æ–‡ä»¶"""
    pattern = f"{symbol}-{year}-{month:02d}-*.csv"
    daily_files = sorted(processed_dir.glob(pattern))
    
    if not daily_files:
        return False
    
    print(f"  åˆå¹¶ {symbol} {year}-{month:02d}: {len(daily_files)}å¤© ... ", end='', flush=True)
    
    try:
        dfs = []
        for f in daily_files:
            df = pd.read_csv(f)
            dfs.append(df)
        
        merged = pd.concat(dfs, ignore_index=True)
        merged['timestamp'] = pd.to_datetime(merged['timestamp'])
        merged = merged.sort_values('timestamp').drop_duplicates()
        
        # ä¿å­˜æœˆåº¦æ–‡ä»¶
        output_file = monthly_dir / f"{symbol}-{year}-{month:02d}.csv"
        merged.to_csv(output_file, index=False)
        
        # åˆ é™¤æ—¥åº¦æ–‡ä»¶
        for f in daily_files:
            f.unlink()
        
        file_size_mb = output_file.stat().st_size // 1024 // 1024
        print(f"âœ“ {len(merged):,}è¡Œ, {file_size_mb}MB")
        return True
        
    except Exception as e:
        print(f"âœ— {e}")
        return False

def main():
    from concurrent.futures import ThreadPoolExecutor
    
    print("="*70)
    print("Binance 1ç§’Kçº¿æ•°æ®ä¸‹è½½å™¨ (å¤šçº¿ç¨‹åŠ é€Ÿç‰ˆ ğŸš€)")
    print("="*70)
    print(f"æ—¶é—´èŒƒå›´: 2024-12-01 åˆ° 2025-12-01")
    print(f"å¸ç§æ•°é‡: {len(TOP_50)}")
    print(f"é¢„è®¡ä¸‹è½½: ~150GB (1å¹´)")
    print("="*70)
    
    # åˆ›å»ºç›®å½•
    raw_dir = Path("/Users/muce/1m_data/1s_data/raw")
    processed_dir = Path("/Users/muce/1m_data/1s_data/processed")
    monthly_dir = Path("/Users/muce/1m_data/1s_data/monthly")
    
    raw_dir.mkdir(parents=True, exist_ok=True)
    processed_dir.mkdir(parents=True, exist_ok=True)
    monthly_dir.mkdir(parents=True, exist_ok=True)
    
    # ç”Ÿæˆæ—¥æœŸåˆ—è¡¨
    start_date = datetime(2024, 12, 1)
    end_date = datetime(2025, 12, 1)
    
    date_list = []
    current = start_date
    while current <= end_date:
        date_list.append(current)
        current += timedelta(days=1)
    
    print(f"\næ€»å¤©æ•°: {len(date_list)}å¤©")
    print(f"æ€»ä¸‹è½½ä»»åŠ¡: {len(TOP_50)} Ã— {len(date_list)} = {len(TOP_50) * len(date_list):,}ä¸ªæ–‡ä»¶")
    
    print("è‡ªåŠ¨å¼€å§‹ä¸‹è½½ (10çº¿ç¨‹å¹¶è¡Œ)...")
    
    # ç»Ÿè®¡
    total_downloaded = 0
    total_failed = 0
    
    # æŒ‰å¸ç§ä¸‹è½½
    for i, symbol in enumerate(TOP_50, 1):
        print(f"\n[{i}/{len(TOP_50)}] {symbol} æ­£åœ¨ä¸‹è½½...")
        
        # å‡†å¤‡ä»»åŠ¡
        tasks = [(symbol, date, raw_dir, processed_dir) for date in date_list]
        
        # å¤šçº¿ç¨‹æ‰§è¡Œ
        with ThreadPoolExecutor(max_workers=10) as executor:
            results = list(executor.map(process_single_date, tasks))
        
        # ç»Ÿè®¡ç»“æœ
        success_count = sum(1 for r in results if r > 0)
        fail_count = len(results) - success_count
        
        total_downloaded += success_count
        total_failed += fail_count
        
        print(f"  {symbol} å®Œæˆ: âœ“{success_count} âœ—{fail_count}")
        
        # åˆå¹¶æœˆåº¦æ–‡ä»¶
        print(f"  åˆå¹¶æœˆåº¦æ–‡ä»¶...")
        for year in [2024, 2025]:
            for month in range(1, 13):
                merge_daily_to_monthly(symbol, year, month, processed_dir, monthly_dir)
    
    print("\n" + "="*70)
    print("ä¸‹è½½å®Œæˆæ‘˜è¦")
    print("="*70)
    print(f"æˆåŠŸ: {total_downloaded:,}ä¸ªæ–‡ä»¶")
    print(f"å¤±è´¥: {total_failed:,}ä¸ªæ–‡ä»¶")
    
    # æ£€æŸ¥ç£ç›˜ä½¿ç”¨
    import subprocess
    result = subprocess.run(['du', '-sh', str(monthly_dir)], capture_output=True, text=True)
    print(f"ç£ç›˜ä½¿ç”¨: {result.stdout.strip()}")
    
    print("\nâœ… æ‰€æœ‰æ•°æ®å·²ä¿å­˜è‡³:", monthly_dir)

if __name__ == "__main__":
    main()
