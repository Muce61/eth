"""
æ•°æ®é¢„å¤„ç†è„šæœ¬: 1m -> 15m åˆå¹¶
(Data Pre-processing: Merge 1m to 15m)

ç›®æ ‡: å°†1åˆ†é’ŸKçº¿æ•°æ®é¢„å…ˆé‡é‡‡æ ·ä¸º15åˆ†é’Ÿæ•°æ®ï¼Œä»¥åŠ é€Ÿå›æµ‹ã€‚
æºç›®å½•: /Users/muce/1m_data/new_backtest_data_1year_1m
ç›®æ ‡ç›®å½•: /Users/muce/1m_data/processed_15m_data
"""

import pandas as pd
from pathlib import Path
import time
from concurrent.futures import ProcessPoolExecutor
import os

# é…ç½®
SOURCE_DIR = Path('/Users/muce/1m_data/new_backtest_data_1year_1m')
TARGET_DIR = Path('/Users/muce/1m_data/processed_15m_data')

def process_file(file_path):
    try:
        # è¯»å–1mæ•°æ®
        df = pd.read_csv(file_path)
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df.set_index('timestamp', inplace=True)
        
        # é‡é‡‡æ ·ä¸º15m
        # è§„åˆ™:
        # Open: ç¬¬ä¸€åˆ†é’Ÿçš„Open
        # High: 15åˆ†é’Ÿå†…çš„æœ€é«˜High
        # Low: 15åˆ†é’Ÿå†…çš„æœ€ä½Low
        # Close: æœ€åä¸€åˆ†é’Ÿçš„Close
        # Volume: 15åˆ†é’ŸVolumeæ€»å’Œ
        df_15m = df.resample('15min').agg({
            'open': 'first',
            'high': 'max',
            'low': 'min',
            'close': 'last',
            'volume': 'sum'
        })
        
        # ç§»é™¤æ— æ•ˆè¡Œ (æ¯”å¦‚ä¸­é—´æœ‰æ–­æ¡£å¯¼è‡´çš„NaN)
        df_15m.dropna(inplace=True)
        
        # é‡ç½®ç´¢å¼•ï¼Œä¿å­˜ä¸ºCSV
        target_path = TARGET_DIR / file_path.name
        df_15m.to_csv(target_path)
        
        return f"âœ“ {file_path.name}: {len(df)} -> {len(df_15m)} rows"
        
    except Exception as e:
        return f"âœ— {file_path.name}: {str(e)}"

def merge_1m_to_15m():
    print("="*80)
    print("ğŸš€ å¼€å§‹æ•°æ®åˆå¹¶: 1m -> 15m")
    print(f"æºç›®å½•: {SOURCE_DIR}")
    print(f"ç›®æ ‡ç›®å½•: {TARGET_DIR}")
    print("="*80)
    
    # åˆ›å»ºç›®æ ‡ç›®å½•
    TARGET_DIR.mkdir(parents=True, exist_ok=True)
    
    # è·å–æ‰€æœ‰CSVæ–‡ä»¶
    files = list(SOURCE_DIR.glob('*.csv'))
    print(f"æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶")
    
    start_time = time.time()
    
    # ä½¿ç”¨å¤šè¿›ç¨‹åŠ é€Ÿå¤„ç†
    # Macä¸Šé€šå¸¸æ ¸æ•°è¾ƒå¤šï¼Œå¹¶è¡Œå¤„ç†IOå¯†é›†å‹ä»»åŠ¡æ•ˆæœå¥½
    max_workers = os.cpu_count() or 4
    print(f"ä½¿ç”¨ {max_workers} ä¸ªè¿›ç¨‹å¹¶è¡Œå¤„ç†...")
    
    success_count = 0
    fail_count = 0
    
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        results = list(executor.map(process_file, files))
        
        for res in results:
            if res.startswith("âœ“"):
                success_count += 1
                # æ¯å®Œæˆ50ä¸ªæ‰“å°ä¸€æ¬¡è¿›åº¦ï¼Œé¿å…åˆ·å±
                if success_count % 50 == 0:
                    print(f"è¿›åº¦: {success_count}/{len(files)}")
            else:
                fail_count += 1
                print(res)
    
    end_time = time.time()
    duration = end_time - start_time
    
    print("\n" + "="*80)
    print("âœ… åˆå¹¶å®Œæˆ!")
    print(f"æˆåŠŸ: {success_count}")
    print(f"å¤±è´¥: {fail_count}")
    print(f"è€—æ—¶: {duration:.2f}ç§’")
    print(f"æ•°æ®å·²ä¿å­˜è‡³: {TARGET_DIR}")
    print("="*80)

if __name__ == "__main__":
    merge_1m_to_15m()
